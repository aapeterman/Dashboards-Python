import plaid
from plaid.api import plaid_api
from plaid.model.transactions_sync_request import TransactionsSyncRequest
from plaid.configuration import Configuration
from plaid.api_client import ApiClient
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import os
from datetime import datetime
from dotenv import load_dotenv
import numpy as np

def clean_nan(value):
    if isinstance(value, float) and (np.isnan(value) or np.isinf(value)):
        return ''
    if isinstance(value, dict):
        return {k: clean_nan(v) for k, v in value.items()}
    if isinstance(value, list):
        return [clean_nan(item) for item in value]
    if value is None:
        return ''
    return value

load_dotenv()

CLIENT_ID = os.getenv('PLAID_CLIENT_ID')
SECRET = os.getenv('PLAID_SECRET')
ENV = os.getenv('PLAID_ENV', 'sandbox')

configuration = Configuration(
    host=getattr(plaid.Environment, ENV.capitalize()),
    api_key={'clientId': CLIENT_ID, 'secret': SECRET}
)
api_client = ApiClient(configuration)
client = plaid_api.PlaidApi(api_client)

scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
gc = gspread.authorize(creds)
spreadsheet = gc.open('Plaid_Transactions')

# Single combined tab for all transactions
WORKSHEET_NAME = 'All Transactions Combined'
try:
    worksheet = spreadsheet.worksheet(WORKSHEET_NAME)
    print(f"Using existing tab: {WORKSHEET_NAME}")
except gspread.exceptions.WorksheetNotFound:
    worksheet = spreadsheet.add_worksheet(title=WORKSHEET_NAME, rows=2000, cols=100)
    print(f"Created new tab: {WORKSHEET_NAME}")

BANK_NAMES = {
    os.getenv('PLAID_ACCESS_TOKEN'): 'ENT Business',
    os.getenv('PLAID_ACCESS_TOKEN_2'): 'ENT Personal',
    os.getenv('PLAID_ACCESS_TOKEN_3'): 'Chase',
}

# Load all tokens
ACCESS_TOKENS = []
token_keys = ['PLAID_ACCESS_TOKEN', 'PLAID_ACCESS_TOKEN_2', 'PLAID_ACCESS_TOKEN_3']
for key in token_keys:
    token = os.getenv(key)
    if token:
        ACCESS_TOKENS.append(token)
        print(f"Loaded token from {key}: {token[:20]}...")

if not ACCESS_TOKENS:
    print("No access tokens found in .env")
    exit()

print(f"Found {len(ACCESS_TOKENS)} tokens to sync")

all_transactions = []

for token in ACCESS_TOKENS:
    bank_name = BANK_NAMES.get(token, 'Unknown Bank')
    print(f"Syncing '{bank_name}' with token {token[:20]}...")

    cursor_file = f'plaid_cursor_{token[:8]}.txt'
    cursor = None
    if os.path.exists(cursor_file):
        with open(cursor_file, 'r') as f:
            cursor = f.read().strip()

    sync_cursor = cursor if cursor is not None else ""

    request = TransactionsSyncRequest(access_token=token, cursor=sync_cursor)

    # Retry on mutation error
    max_retries = 3
    response = None
    for attempt in range(max_retries):
        try:
            response = client.transactions_sync(request)
            break
        except plaid.exceptions.ApiException as e:
            if "MUTATION_DURING_PAGINATION" in str(e) or "cursor" in str(e).lower():
                print(f"Mutation/cursor error on attempt {attempt+1} â€” resetting cursor and retrying...")
                sync_cursor = ""
                request.cursor = sync_cursor
            else:
                raise e
    if response is None:
        print(f"Max retries exceeded for token {token[:20]}")
        continue

    transactions = response['added'] + response['modified']

    # Tag each transaction with bank name
    for t in transactions:
        t['bank_name'] = bank_name

    all_transactions.extend(transactions)

    if response['next_cursor']:
        with open(cursor_file, 'w') as f:
            f.write(response['next_cursor'])

    print(f"Added/updated {len(transactions)} transactions from '{bank_name}'")

# Process combined transactions
if all_transactions:
    df_new = pd.DataFrame([t.to_dict() for t in all_transactions])

    # Flatten/stringify nested fields
    for col in df_new.columns:
        df_new[col] = df_new[col].apply(lambda x: json.dumps(x, default=str) if isinstance(x, (list, dict)) else ('' if pd.isna(x) else str(x)))

    # Deep clean (this fixes nan crash)
    df_new = df_new.map(clean_nan)

    # Add Year, Month, Day
    if 'date' in df_new.columns:
        df_new['Year'] = df_new['date'].apply(lambda x: x[:4] if x and len(x) >= 4 else '')
        df_new['Month'] = df_new['date'].apply(lambda x: x[5:7] if x and len(x) >= 7 else '')
        df_new['Day'] = df_new['date'].apply(lambda x: x[8:10] if x and len(x) >= 10 else '')

    # Add Bank Name column
    df_new['Bank Name'] = df_new['bank_name']

    # Drop temporary bank_name column if you don't want it
    if 'bank_name' in df_new.columns:
        df_new = df_new.drop(columns=['bank_name'])

    # Append to the single combined tab
    existing_data = worksheet.get_all_records()
    if existing_data:
        df_existing = pd.DataFrame(existing_data)
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        df_combined.drop_duplicates(subset=['transaction_id'], keep='last', inplace=True)
        worksheet.update([df_combined.columns.values.tolist()] + df_combined.values.tolist())
    else:
        worksheet.update([df_new.columns.values.tolist()] + df_new.values.tolist())

    print(f"Total added/updated {len(df_new)} transactions in '{WORKSHEET_NAME}'")
else:
    print("No new transactions")

print("Sync complete for all banks.")
